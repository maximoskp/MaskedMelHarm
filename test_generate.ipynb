{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e491e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import GridMLMMelHarm\n",
    "from GridMLM_tokenizers import CSGridMLMTokenizer\n",
    "from data_utils import CSGridMLMDataset, CSGridMLM_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from train_utils import apply_masking\n",
    "from generate_utils import random_progressive_generate, structured_progressive_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad30c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "val_dir = '/media/maindisk/maximos/data/hooktheory_all12_test'\n",
    "tokenizer = CSGridMLMTokenizer(fixed_length=256)\n",
    "val_dataset = CSGridMLMDataset(val_dir, tokenizer, 512)\n",
    "valloader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False, collate_fn=CSGridMLM_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6845a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_id = tokenizer.mask_token_id\n",
    "stage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02945c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridMLMMelHarm(\n",
       "  (condition_proj): Linear(in_features=16, out_features=512, bias=True)\n",
       "  (melody_proj): Linear(in_features=100, out_features=512, bias=True)\n",
       "  (harmony_embedding): Embedding(354, 512)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (stage_embedding): Embedding(10, 64)\n",
       "  (stage_proj): Linear(in_features=576, out_features=512, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Linear(in_features=512, out_features=354, bias=True)\n",
       "  (input_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_type = 'random'\n",
    "device_name = 'cuda:1'\n",
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)\n",
    "model = GridMLMMelHarm(\n",
    "    chord_vocab_size=len(tokenizer.vocab),\n",
    "    device=device\n",
    ")\n",
    "model_path = 'saved_models/' + curriculum_type +  '.pt'\n",
    "# checkpoint = torch.load(model_path, map_location=device_name, weights_only=True)\n",
    "checkpoint = torch.load(model_path, map_location=device_name)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa1cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in valloader:\n",
    "    if i == 30:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_grid = batch[\"pianoroll\"].to(device)           # (B, 256, 140)\n",
    "harmony_gt = batch[\"input_ids\"].to(device)         # (B, 256)\n",
    "conditioning_vec = batch[\"time_signature\"].to(device)  # (B, C0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bcc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_harmony = random_progressive_generate(\n",
    "    model=model,\n",
    "    melody_grid=melody_grid,\n",
    "    conditioning_vec=conditioning_vec,\n",
    "    num_stages=10,\n",
    "    mask_token_id=tokenizer.mask_token_id,\n",
    "    temperature=1.0,\n",
    "    strategy='topk'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd0b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_harmony: tensor([[  6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
      "         296, 296, 296, 296,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6, 296, 296, 296, 296,\n",
      "         296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
      "         296, 296, 296, 296, 296, 296,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6, 296, 296,\n",
      "         296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6]], device='cuda:1')\n",
      "output_tokens\n",
      "['0:C:maj', '1:C:maj', '2:C:maj', '3:C:maj', '4:C:maj', '5:C:maj', '6:C:maj', '7:C:maj', '8:C:maj', '9:C:maj', '10:C:maj', '11:C:maj', '12:C:maj', '13:C:maj', '14:C:maj', '15:C:maj', '16:A#:maj', '17:A#:maj', '18:A#:maj', '19:A#:maj', '20:A#:maj', '21:A#:maj', '22:A#:maj', '23:A#:maj', '24:A#:maj', '25:A#:maj', '26:A#:maj', '27:A#:maj', '28:A#:maj', '29:A#:maj', '30:A#:maj', '31:A#:maj', '32:C:maj', '33:C:maj', '34:C:maj', '35:C:maj', '36:C:maj', '37:C:maj', '38:C:maj', '39:C:maj', '40:C:maj', '41:C:maj', '42:C:maj', '43:C:maj', '44:C:maj', '45:C:maj', '46:C:maj', '47:C:maj', '48:C:maj', '49:C:maj', '50:C:maj', '51:C:maj', '52:C:maj', '53:C:maj', '54:C:maj', '55:C:maj', '56:C:maj', '57:C:maj', '58:C:maj', '59:C:maj', '60:C:maj', '61:C:maj', '62:C:maj', '63:C:maj', '64:C:maj', '65:C:maj', '66:C:maj', '67:C:maj', '68:C:maj', '69:C:maj', '70:C:maj', '71:C:maj', '72:C:maj', '73:C:maj', '74:C:maj', '75:C:maj', '76:C:maj', '77:C:maj', '78:C:maj', '79:C:maj', '80:A#:maj', '81:A#:maj', '82:A#:maj', '83:A#:maj', '84:A#:maj', '85:A#:maj', '86:A#:maj', '87:A#:maj', '88:A#:maj', '89:A#:maj', '90:A#:maj', '91:A#:maj', '92:A#:maj', '93:A#:maj', '94:A#:maj', '95:A#:maj', '96:C:maj', '97:C:maj', '98:C:maj', '99:C:maj', '100:C:maj', '101:C:maj', '102:C:maj', '103:C:maj', '104:C:maj', '105:C:maj', '106:C:maj', '107:C:maj', '108:C:maj', '109:C:maj', '110:C:maj', '111:C:maj', '112:C:maj', '113:C:maj', '114:C:maj', '115:C:maj', '116:C:maj', '117:C:maj', '118:C:maj', '119:C:maj', '120:C:maj', '121:C:maj', '122:C:maj', '123:C:maj', '124:C:maj', '125:C:maj', '126:C:maj', '127:C:maj', '128:C:maj', '129:C:maj', '130:C:maj', '131:C:maj', '132:C:maj', '133:C:maj', '134:C:maj', '135:C:maj', '136:C:maj', '137:C:maj', '138:C:maj', '139:C:maj', '140:C:maj', '141:C:maj', '142:C:maj', '143:C:maj', '144:A#:maj', '145:A#:maj', '146:A#:maj', '147:A#:maj', '148:A#:maj', '149:A#:maj', '150:A#:maj', '151:A#:maj', '152:A#:maj', '153:A#:maj', '154:A#:maj', '155:A#:maj', '156:A#:maj', '157:A#:maj', '158:A#:maj', '159:A#:maj', '160:C:maj', '161:C:maj', '162:C:maj', '163:C:maj', '164:C:maj', '165:C:maj', '166:C:maj', '167:C:maj', '168:C:maj', '169:C:maj', '170:C:maj', '171:C:maj', '172:C:maj', '173:C:maj', '174:C:maj', '175:C:maj', '176:C:maj', '177:C:maj', '178:C:maj', '179:C:maj', '180:C:maj', '181:C:maj', '182:C:maj', '183:C:maj', '184:C:maj', '185:C:maj', '186:C:maj', '187:C:maj', '188:C:maj', '189:C:maj', '190:C:maj', '191:C:maj', '192:C:maj', '193:C:maj', '194:C:maj', '195:C:maj', '196:C:maj', '197:C:maj', '198:C:maj', '199:C:maj', '200:C:maj', '201:C:maj', '202:C:maj', '203:C:maj', '204:C:maj', '205:C:maj', '206:C:maj', '207:C:maj', '208:A#:maj', '209:A#:maj', '210:A#:maj', '211:A#:maj', '212:A#:maj', '213:A#:maj', '214:A#:maj', '215:A#:maj', '216:A#:maj', '217:A#:maj', '218:A#:maj', '219:A#:maj', '220:A#:maj', '221:A#:maj', '222:A#:maj', '223:A#:maj', '224:C:maj', '225:C:maj', '226:C:maj', '227:C:maj', '228:C:maj', '229:C:maj', '230:C:maj', '231:C:maj', '232:C:maj', '233:C:maj', '234:C:maj', '235:C:maj', '236:C:maj', '237:C:maj', '238:C:maj', '239:C:maj', '240:C:maj', '241:C:maj', '242:C:maj', '243:C:maj', '244:C:maj', '245:C:maj', '246:C:maj', '247:C:maj', '248:C:maj', '249:C:maj', '250:C:maj', '251:C:maj', '252:C:maj', '253:C:maj', '254:C:maj', '255:C:maj']\n",
      "harmony_gt_tokens\n",
      "['0:G:maj', '1:G:maj', '2:G:maj', '3:G:maj', '4:G:maj', '5:G:maj', '6:G:maj', '7:G:maj', '8:G:maj', '9:G:maj', '10:G:maj', '11:G:maj', '12:G:maj', '13:G:maj', '14:G:maj', '15:G:maj', '16:A#:maj', '17:A#:maj', '18:A#:maj', '19:A#:maj', '20:A#:maj', '21:A#:maj', '22:A#:maj', '23:A#:maj', '24:A#:maj', '25:A#:maj', '26:A#:maj', '27:A#:maj', '28:A#:maj', '29:A#:maj', '30:A#:maj', '31:A#:maj', '32:F:maj', '33:F:maj', '34:F:maj', '35:F:maj', '36:F:maj', '37:F:maj', '38:F:maj', '39:F:maj', '40:F:maj', '41:F:maj', '42:F:maj', '43:F:maj', '44:F:maj', '45:F:maj', '46:F:maj', '47:F:maj', '48:C:maj', '49:C:maj', '50:C:maj', '51:C:maj', '52:C:maj', '53:C:maj', '54:C:maj', '55:C:maj', '56:C:maj', '57:C:maj', '58:C:maj', '59:C:maj', '60:C:maj', '61:C:maj', '62:C:maj', '63:C:maj', '64:G:maj', '65:G:maj', '66:G:maj', '67:G:maj', '68:G:maj', '69:G:maj', '70:G:maj', '71:G:maj', '72:G:maj', '73:G:maj', '74:G:maj', '75:G:maj', '76:G:maj', '77:G:maj', '78:G:maj', '79:G:maj', '80:A#:maj', '81:A#:maj', '82:A#:maj', '83:A#:maj', '84:A#:maj', '85:A#:maj', '86:A#:maj', '87:A#:maj', '88:A#:maj', '89:A#:maj', '90:A#:maj', '91:A#:maj', '92:A#:maj', '93:A#:maj', '94:A#:maj', '95:A#:maj', '96:F:maj', '97:F:maj', '98:F:maj', '99:F:maj', '100:F:maj', '101:F:maj', '102:F:maj', '103:F:maj', '104:F:maj', '105:F:maj', '106:F:maj', '107:F:maj', '108:F:maj', '109:F:maj', '110:F:maj', '111:F:maj', '112:C:maj', '113:C:maj', '114:C:maj', '115:C:maj', '116:C:maj', '117:C:maj', '118:C:maj', '119:C:maj', '120:C:maj', '121:C:maj', '122:C:maj', '123:C:maj', '124:C:maj', '125:C:maj', '126:C:maj', '127:C:maj', '128:D#:maj', '129:D#:maj', '130:D#:maj', '131:D#:maj', '132:D#:maj', '133:D#:maj', '134:D#:maj', '135:D#:maj', '136:D#:maj', '137:D#:maj', '138:D#:maj', '139:D#:maj', '140:D#:maj', '141:D#:maj', '142:D#:maj', '143:D#:maj', '144:A#:maj', '145:A#:maj', '146:A#:maj', '147:A#:maj', '148:A#:maj', '149:A#:maj', '150:A#:maj', '151:A#:maj', '152:A#:maj', '153:A#:maj', '154:A#:maj', '155:A#:maj', '156:A#:maj', '157:A#:maj', '158:A#:maj', '159:A#:maj', '160:F:maj', '161:F:maj', '162:F:maj', '163:F:maj', '164:F:maj', '165:F:maj', '166:F:maj', '167:F:maj', '168:F:maj', '169:F:maj', '170:F:maj', '171:F:maj', '172:F:maj', '173:F:maj', '174:F:maj', '175:F:maj', '176:F:maj', '177:F:maj', '178:F:maj', '179:F:maj', '180:F:maj', '181:F:maj', '182:G:maj', '183:G:maj', '184:G:maj', '185:G:maj', '186:G:maj', '187:G:maj', '188:F:maj', '189:F:maj', '190:F:maj', '191:F:maj', '192:D#:maj', '193:D#:maj', '194:D#:maj', '195:D#:maj', '196:D#:maj', '197:D#:maj', '198:D#:maj', '199:D#:maj', '200:D#:maj', '201:D#:maj', '202:D#:maj', '203:D#:maj', '204:D#:maj', '205:D#:maj', '206:D#:maj', '207:D#:maj', '208:A#:maj', '209:A#:maj', '210:A#:maj', '211:A#:maj', '212:A#:maj', '213:A#:maj', '214:A#:maj', '215:A#:maj', '216:A#:maj', '217:A#:maj', '218:A#:maj', '219:A#:maj', '220:A#:maj', '221:A#:maj', '222:A#:maj', '223:A#:maj', '224:F:maj', '225:F:maj', '226:F:maj', '227:F:maj', '228:F:maj', '229:F:maj', '230:F:maj', '231:F:maj', '232:F:maj', '233:F:maj', '234:F:maj', '235:F:maj', '236:F:maj', '237:F:maj', '238:F:maj', '239:F:maj', '240:F:maj', '241:F:maj', '242:F:maj', '243:F:maj', '244:F:maj', '245:F:maj', '246:D:maj', '247:D:maj', '248:D:maj', '249:D:maj', '250:D:maj', '251:D:maj', '252:D:maj', '253:D:maj', '254:D:maj', '255:D:maj']\n"
     ]
    }
   ],
   "source": [
    "print('generated_harmony:', generated_harmony)\n",
    "output_tokens = []\n",
    "for i,t in enumerate(generated_harmony[0].tolist()):\n",
    "    output_tokens.append( str(i) + ':' + tokenizer.ids_to_tokens[t] )\n",
    "print('output_tokens')\n",
    "print(output_tokens)\n",
    "\n",
    "harmony_gt_tokens = []\n",
    "for i,t in enumerate(harmony_gt[0].tolist()):\n",
    "    harmony_gt_tokens.append( str(i) + ':' + tokenizer.ids_to_tokens[t] )\n",
    "print('harmony_gt_tokens')\n",
    "print(harmony_gt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1f5079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridMLMMelHarm(\n",
       "  (condition_proj): Linear(in_features=16, out_features=512, bias=True)\n",
       "  (melody_proj): Linear(in_features=100, out_features=512, bias=True)\n",
       "  (harmony_embedding): Embedding(354, 512)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (stage_embedding): Embedding(10, 64)\n",
       "  (stage_proj): Linear(in_features=576, out_features=512, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Linear(in_features=512, out_features=354, bias=True)\n",
       "  (input_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_type = 'base2'\n",
    "device_name = 'cuda:1'\n",
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)\n",
    "model = GridMLMMelHarm(\n",
    "    chord_vocab_size=len(tokenizer.vocab),\n",
    "    device=device\n",
    ")\n",
    "model_path = 'saved_models/' + curriculum_type +  '.pt'\n",
    "# checkpoint = torch.load(model_path, map_location=device_name, weights_only=True)\n",
    "checkpoint = torch.load(model_path, map_location=device_name)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc4a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_harmony = structured_progressive_generate(\n",
    "    model=model,\n",
    "    melody_grid=melody_grid,\n",
    "    conditioning_vec=conditioning_vec,\n",
    "    num_stages=10,\n",
    "    mask_token_id=tokenizer.mask_token_id,\n",
    "    temperature=1.0,\n",
    "    strategy='topk'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be0c830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_harmony: tensor([[210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "         210, 210, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,\n",
      "         296, 296, 296, 296,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6, 210, 210, 210, 210, 210, 210,\n",
      "         210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 296, 296, 296, 296,\n",
      "         296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296, 296,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "         210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "         210, 210, 210, 210, 210, 210, 151, 151, 151, 151, 151, 151, 151, 151,\n",
      "         151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151,\n",
      "         151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 210, 210, 210, 210,\n",
      "         210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "         210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6]], device='cuda:1')\n",
      "output_tokens\n",
      "['0:G:min', '1:G:min', '2:G:min', '3:G:min', '4:G:min', '5:G:min', '6:G:min', '7:G:min', '8:G:min', '9:G:min', '10:G:min', '11:G:min', '12:G:min', '13:G:min', '14:G:min', '15:G:min', '16:A#:maj', '17:A#:maj', '18:A#:maj', '19:A#:maj', '20:A#:maj', '21:A#:maj', '22:A#:maj', '23:A#:maj', '24:A#:maj', '25:A#:maj', '26:A#:maj', '27:A#:maj', '28:A#:maj', '29:A#:maj', '30:A#:maj', '31:A#:maj', '32:C:maj', '33:C:maj', '34:C:maj', '35:C:maj', '36:C:maj', '37:C:maj', '38:C:maj', '39:C:maj', '40:C:maj', '41:C:maj', '42:C:maj', '43:C:maj', '44:C:maj', '45:C:maj', '46:C:maj', '47:C:maj', '48:C:maj', '49:C:maj', '50:C:maj', '51:C:maj', '52:C:maj', '53:C:maj', '54:C:maj', '55:C:maj', '56:C:maj', '57:C:maj', '58:C:maj', '59:C:maj', '60:C:maj', '61:C:maj', '62:C:maj', '63:C:maj', '64:G:min', '65:G:min', '66:G:min', '67:G:min', '68:G:min', '69:G:min', '70:G:min', '71:G:min', '72:G:min', '73:G:min', '74:G:min', '75:G:min', '76:G:min', '77:G:min', '78:G:min', '79:G:min', '80:A#:maj', '81:A#:maj', '82:A#:maj', '83:A#:maj', '84:A#:maj', '85:A#:maj', '86:A#:maj', '87:A#:maj', '88:A#:maj', '89:A#:maj', '90:A#:maj', '91:A#:maj', '92:A#:maj', '93:A#:maj', '94:A#:maj', '95:A#:maj', '96:C:maj', '97:C:maj', '98:C:maj', '99:C:maj', '100:C:maj', '101:C:maj', '102:C:maj', '103:C:maj', '104:C:maj', '105:C:maj', '106:C:maj', '107:C:maj', '108:C:maj', '109:C:maj', '110:C:maj', '111:C:maj', '112:C:maj', '113:C:maj', '114:C:maj', '115:C:maj', '116:C:maj', '117:C:maj', '118:C:maj', '119:C:maj', '120:C:maj', '121:C:maj', '122:C:maj', '123:C:maj', '124:C:maj', '125:C:maj', '126:C:maj', '127:C:maj', '128:G:min', '129:G:min', '130:G:min', '131:G:min', '132:G:min', '133:G:min', '134:G:min', '135:G:min', '136:G:min', '137:G:min', '138:G:min', '139:G:min', '140:G:min', '141:G:min', '142:G:min', '143:G:min', '144:G:min', '145:G:min', '146:G:min', '147:G:min', '148:G:min', '149:G:min', '150:G:min', '151:G:min', '152:G:min', '153:G:min', '154:G:min', '155:G:min', '156:G:min', '157:G:min', '158:G:min', '159:G:min', '160:F:maj', '161:F:maj', '162:F:maj', '163:F:maj', '164:F:maj', '165:F:maj', '166:F:maj', '167:F:maj', '168:F:maj', '169:F:maj', '170:F:maj', '171:F:maj', '172:F:maj', '173:F:maj', '174:F:maj', '175:F:maj', '176:F:maj', '177:F:maj', '178:F:maj', '179:F:maj', '180:F:maj', '181:F:maj', '182:F:maj', '183:F:maj', '184:F:maj', '185:F:maj', '186:F:maj', '187:F:maj', '188:F:maj', '189:F:maj', '190:F:maj', '191:F:maj', '192:G:min', '193:G:min', '194:G:min', '195:G:min', '196:G:min', '197:G:min', '198:G:min', '199:G:min', '200:G:min', '201:G:min', '202:G:min', '203:G:min', '204:G:min', '205:G:min', '206:G:min', '207:G:min', '208:G:min', '209:G:min', '210:G:min', '211:G:min', '212:G:min', '213:G:min', '214:G:min', '215:G:min', '216:G:min', '217:G:min', '218:G:min', '219:G:min', '220:G:min', '221:G:min', '222:G:min', '223:G:min', '224:C:maj', '225:C:maj', '226:C:maj', '227:C:maj', '228:C:maj', '229:C:maj', '230:C:maj', '231:C:maj', '232:C:maj', '233:C:maj', '234:C:maj', '235:C:maj', '236:C:maj', '237:C:maj', '238:C:maj', '239:C:maj', '240:C:maj', '241:C:maj', '242:C:maj', '243:C:maj', '244:C:maj', '245:C:maj', '246:C:maj', '247:C:maj', '248:C:maj', '249:C:maj', '250:C:maj', '251:C:maj', '252:C:maj', '253:C:maj', '254:C:maj', '255:C:maj']\n",
      "harmony_gt_tokens\n",
      "['0:G:maj', '1:G:maj', '2:G:maj', '3:G:maj', '4:G:maj', '5:G:maj', '6:G:maj', '7:G:maj', '8:G:maj', '9:G:maj', '10:G:maj', '11:G:maj', '12:G:maj', '13:G:maj', '14:G:maj', '15:G:maj', '16:A#:maj', '17:A#:maj', '18:A#:maj', '19:A#:maj', '20:A#:maj', '21:A#:maj', '22:A#:maj', '23:A#:maj', '24:A#:maj', '25:A#:maj', '26:A#:maj', '27:A#:maj', '28:A#:maj', '29:A#:maj', '30:A#:maj', '31:A#:maj', '32:F:maj', '33:F:maj', '34:F:maj', '35:F:maj', '36:F:maj', '37:F:maj', '38:F:maj', '39:F:maj', '40:F:maj', '41:F:maj', '42:F:maj', '43:F:maj', '44:F:maj', '45:F:maj', '46:F:maj', '47:F:maj', '48:C:maj', '49:C:maj', '50:C:maj', '51:C:maj', '52:C:maj', '53:C:maj', '54:C:maj', '55:C:maj', '56:C:maj', '57:C:maj', '58:C:maj', '59:C:maj', '60:C:maj', '61:C:maj', '62:C:maj', '63:C:maj', '64:G:maj', '65:G:maj', '66:G:maj', '67:G:maj', '68:G:maj', '69:G:maj', '70:G:maj', '71:G:maj', '72:G:maj', '73:G:maj', '74:G:maj', '75:G:maj', '76:G:maj', '77:G:maj', '78:G:maj', '79:G:maj', '80:A#:maj', '81:A#:maj', '82:A#:maj', '83:A#:maj', '84:A#:maj', '85:A#:maj', '86:A#:maj', '87:A#:maj', '88:A#:maj', '89:A#:maj', '90:A#:maj', '91:A#:maj', '92:A#:maj', '93:A#:maj', '94:A#:maj', '95:A#:maj', '96:F:maj', '97:F:maj', '98:F:maj', '99:F:maj', '100:F:maj', '101:F:maj', '102:F:maj', '103:F:maj', '104:F:maj', '105:F:maj', '106:F:maj', '107:F:maj', '108:F:maj', '109:F:maj', '110:F:maj', '111:F:maj', '112:C:maj', '113:C:maj', '114:C:maj', '115:C:maj', '116:C:maj', '117:C:maj', '118:C:maj', '119:C:maj', '120:C:maj', '121:C:maj', '122:C:maj', '123:C:maj', '124:C:maj', '125:C:maj', '126:C:maj', '127:C:maj', '128:D#:maj', '129:D#:maj', '130:D#:maj', '131:D#:maj', '132:D#:maj', '133:D#:maj', '134:D#:maj', '135:D#:maj', '136:D#:maj', '137:D#:maj', '138:D#:maj', '139:D#:maj', '140:D#:maj', '141:D#:maj', '142:D#:maj', '143:D#:maj', '144:A#:maj', '145:A#:maj', '146:A#:maj', '147:A#:maj', '148:A#:maj', '149:A#:maj', '150:A#:maj', '151:A#:maj', '152:A#:maj', '153:A#:maj', '154:A#:maj', '155:A#:maj', '156:A#:maj', '157:A#:maj', '158:A#:maj', '159:A#:maj', '160:F:maj', '161:F:maj', '162:F:maj', '163:F:maj', '164:F:maj', '165:F:maj', '166:F:maj', '167:F:maj', '168:F:maj', '169:F:maj', '170:F:maj', '171:F:maj', '172:F:maj', '173:F:maj', '174:F:maj', '175:F:maj', '176:F:maj', '177:F:maj', '178:F:maj', '179:F:maj', '180:F:maj', '181:F:maj', '182:G:maj', '183:G:maj', '184:G:maj', '185:G:maj', '186:G:maj', '187:G:maj', '188:F:maj', '189:F:maj', '190:F:maj', '191:F:maj', '192:D#:maj', '193:D#:maj', '194:D#:maj', '195:D#:maj', '196:D#:maj', '197:D#:maj', '198:D#:maj', '199:D#:maj', '200:D#:maj', '201:D#:maj', '202:D#:maj', '203:D#:maj', '204:D#:maj', '205:D#:maj', '206:D#:maj', '207:D#:maj', '208:A#:maj', '209:A#:maj', '210:A#:maj', '211:A#:maj', '212:A#:maj', '213:A#:maj', '214:A#:maj', '215:A#:maj', '216:A#:maj', '217:A#:maj', '218:A#:maj', '219:A#:maj', '220:A#:maj', '221:A#:maj', '222:A#:maj', '223:A#:maj', '224:F:maj', '225:F:maj', '226:F:maj', '227:F:maj', '228:F:maj', '229:F:maj', '230:F:maj', '231:F:maj', '232:F:maj', '233:F:maj', '234:F:maj', '235:F:maj', '236:F:maj', '237:F:maj', '238:F:maj', '239:F:maj', '240:F:maj', '241:F:maj', '242:F:maj', '243:F:maj', '244:F:maj', '245:F:maj', '246:D:maj', '247:D:maj', '248:D:maj', '249:D:maj', '250:D:maj', '251:D:maj', '252:D:maj', '253:D:maj', '254:D:maj', '255:D:maj']\n"
     ]
    }
   ],
   "source": [
    "print('generated_harmony:', generated_harmony)\n",
    "output_tokens = []\n",
    "for i,t in enumerate(generated_harmony[0].tolist()):\n",
    "    output_tokens.append( str(i) + ':' + tokenizer.ids_to_tokens[t] )\n",
    "print('output_tokens')\n",
    "print(output_tokens)\n",
    "\n",
    "harmony_gt_tokens = []\n",
    "for i,t in enumerate(harmony_gt[0].tolist()):\n",
    "    harmony_gt_tokens.append( str(i) + ':' + tokenizer.ids_to_tokens[t] )\n",
    "print('harmony_gt_tokens')\n",
    "print(harmony_gt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b8c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10486\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_files = []\n",
    "for dirpath, _, filenames in os.walk(val_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.xml') or file.endswith('.mxl') or file.endswith('.musicxml'):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "            data_files.append(full_path)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "797e6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(data_files[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dffcc448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_tokens', 'input_ids', 'pianoroll', 'time_signature', 'attention_mask', 'skip_steps', 'melody_part', 'ql_per_quantum'])\n"
     ]
    }
   ],
   "source": [
    "print(encoded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52a3756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_grid = torch.stack([torch.tensor(encoded['pianoroll'], dtype=torch.float)])\n",
    "conditioning_vec = torch.stack([torch.tensor(encoded['time_signature'], dtype=torch.float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf7caa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_harmony = structured_progressive_generate(\n",
    "    model=model,\n",
    "    melody_grid=melody_grid,\n",
    "    conditioning_vec=conditioning_vec,\n",
    "    num_stages=10,\n",
    "    mask_token_id=tokenizer.mask_token_id,\n",
    "    temperature=1.0,\n",
    "    strategy='topk'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30a895ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tokens\n",
      "['B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'F#:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', 'B:maj', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "harmony_gt_tokens\n",
      "['G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'A#:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj', 'D:maj']\n"
     ]
    }
   ],
   "source": [
    "output_tokens = []\n",
    "for i,t in enumerate(generated_harmony[0].tolist()):\n",
    "    output_tokens.append( tokenizer.ids_to_tokens[t] )\n",
    "print('output_tokens')\n",
    "print(output_tokens)\n",
    "\n",
    "harmony_gt_tokens = []\n",
    "for i,t in enumerate(harmony_gt[0].tolist()):\n",
    "    harmony_gt_tokens.append( tokenizer.ids_to_tokens[t] )\n",
    "print('harmony_gt_tokens')\n",
    "print(harmony_gt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af228e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import harmony, stream, metadata, chord, meter\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def overlay_generated_harmony(melody_part, generated_chords, ql_per_16th, skip_steps):\n",
    "    # create a part for chords in midi format\n",
    "    chords_part = stream.Part()\n",
    "    # Create deep copy of flat melody part\n",
    "    harmonized_part = deepcopy(melody_part)\n",
    "    \n",
    "    # Remove old chord symbols\n",
    "    for el in harmonized_part.recurse().getElementsByClass(harmony.ChordSymbol):\n",
    "        harmonized_part.remove(el)\n",
    "\n",
    "    # Track inserted chords\n",
    "    last_chord_symbol = None\n",
    "    inserted_chords = {}\n",
    "\n",
    "    for i, mir_chord in enumerate(generated_chords):\n",
    "        if mir_chord in (\"<pad>\", \"<nc>\"):\n",
    "            continue\n",
    "        if mir_chord == last_chord_symbol:\n",
    "            continue\n",
    "\n",
    "        offset = (i + skip_steps) * ql_per_16th\n",
    "\n",
    "        # Decode mir_eval chord symbol to chord symbol object\n",
    "        try:\n",
    "            r, t, _ = mir_eval.chord.encode(mir_chord, reduce_extended_chords=True)\n",
    "            pcs = r + np.where(t > 0)[0] + 48\n",
    "            c = chord.Chord(pcs.tolist())\n",
    "            chord_symbol = harmony.chordSymbolFromChord(c)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping invalid chord {mir_chord} at step {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # harmonized_part.insert(offset, chord_symbol)\n",
    "        chords_part.insert(offset, c)\n",
    "        inserted_chords[i] = chord_symbol\n",
    "        last_chord_symbol = mir_chord\n",
    "\n",
    "    # Convert flat part to one with measures\n",
    "    harmonized_with_measures = harmonized_part.makeMeasures()\n",
    "\n",
    "    # Repeat previous chord at start of bars with no chord\n",
    "    for m in harmonized_with_measures.getElementsByClass(stream.Measure):\n",
    "        bar_offset = m.offset\n",
    "        # has_chord = any(isinstance(el, harmony.ChordSymbol) and el.offset == bar_offset for el in m)\n",
    "        # has_chord = any( isinstance(el, harmony.ChordSymbol) for el in m )\n",
    "        has_chord = any(isinstance(el, harmony.ChordSymbol) and el.offset == 0. for el in m)\n",
    "        if not has_chord:\n",
    "            # Find previous chord before this measure\n",
    "            prev_chords = [el for el in harmonized_part.recurse().getElementsByClass(harmony.ChordSymbol)\n",
    "                           if el.offset < bar_offset]\n",
    "            if prev_chords:\n",
    "                prev_chord = prev_chords[-1]\n",
    "                m.insert(0.0, deepcopy(prev_chord))\n",
    "    \n",
    "    # Convert flat part to one with measures\n",
    "    chords_with_measures = chords_part.makeMeasures()\n",
    "\n",
    "    # Repeat previous chord at start of bars with no chord\n",
    "    for m in chords_with_measures.getElementsByClass(stream.Measure):\n",
    "        bar_offset = m.offset\n",
    "        # has_chord = any(isinstance(el, chord.Chord) and el.offset == bar_offset for el in m)\n",
    "        # has_chord = any( isinstance(el, chord.Chord) for el in m )\n",
    "        has_chord = any(isinstance(el, chord.Chord) and el.offset == 0. for el in m)\n",
    "        if not has_chord:\n",
    "            # Find previous chord before this measure\n",
    "            prev_chords = [el for el in chords_part.recurse().getElementsByClass(chord.Chord)\n",
    "                           if el.offset < bar_offset]\n",
    "            if prev_chords:\n",
    "                prev_chord = prev_chords[-1]\n",
    "                m.insert(0.0, deepcopy(prev_chord))\n",
    "\n",
    "    # Create final score with chords and melody\n",
    "    score = stream.Score()\n",
    "    score.insert(0, harmonized_with_measures)\n",
    "    score.insert(0, chords_with_measures)\n",
    "\n",
    "    return score\n",
    "# end overlay_generated_harmony\n",
    "\n",
    "def save_harmonized_score(score, title=\"Harmonized Piece\", out_path=\"harmonized.xml\"):\n",
    "    score.metadata = metadata.Metadata()\n",
    "    score.metadata.title = title\n",
    "    score.write('musicxml', fp=out_path)\n",
    "# end save_harmonized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99e6d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = overlay_generated_harmony(encoded['melody_part'], output_tokens, encoded['ql_per_quantum'], encoded['skip_steps'])\n",
    "save_harmonized_score(score, out_path=\"harmonized_output.mxl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
