{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e491e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import GridMLMMelHarm\n",
    "from GridMLM_tokenizers import CSGridMLMTokenizer\n",
    "from data_utils import CSGridMLMDataset, CSGridMLM_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from train_utils import apply_masking\n",
    "from generate_utils import random_progressive_generate, structured_progressive_generate,\\\n",
    "    load_model, overlay_generated_harmony, save_harmonized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad30c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = '/media/maindisk/maximos/data/hooktheory_all12_test'\n",
    "tokenizer = CSGridMLMTokenizer(fixed_length=256)\n",
    "val_dataset = CSGridMLMDataset(val_dir, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6845a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_id = tokenizer.mask_token_id\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "nc_token_id = tokenizer.nc_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02945c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridMLMMelHarm(\n",
       "  (condition_proj): Linear(in_features=16, out_features=512, bias=True)\n",
       "  (melody_proj): Linear(in_features=100, out_features=512, bias=True)\n",
       "  (harmony_embedding): Embedding(354, 512)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (stage_embedding): Embedding(10, 64)\n",
       "  (stage_proj): Linear(in_features=576, out_features=512, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Linear(in_features=512, out_features=354, bias=True)\n",
       "  (input_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curriculum_type = 'random'\n",
    "device_name = 'cuda:1'\n",
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)\n",
    "model = GridMLMMelHarm(\n",
    "    chord_vocab_size=len(tokenizer.vocab),\n",
    "    device=device\n",
    ")\n",
    "model_path = 'saved_models/' + curriculum_type +  '.pt'\n",
    "# checkpoint = torch.load(model_path, map_location=device_name, weights_only=True)\n",
    "checkpoint = torch.load(model_path, map_location=device_name)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b8c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10486\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_files = []\n",
    "for dirpath, _, filenames in os.walk(val_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.xml') or file.endswith('.mxl') or file.endswith('.musicxml'):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "            data_files.append(full_path)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797e6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(data_files[1473])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffcc448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_tokens', 'input_ids', 'pianoroll', 'time_signature', 'attention_mask', 'skip_steps', 'melody_part', 'ql_per_quantum'])\n"
     ]
    }
   ],
   "source": [
    "print(encoded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52a3756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_grid = torch.stack([torch.tensor(encoded['pianoroll'], dtype=torch.float)])\n",
    "conditioning_vec = torch.stack([torch.tensor(encoded['time_signature'], dtype=torch.float)])\n",
    "harmony_gt = torch.stack([torch.tensor(encoded['input_ids'], dtype=torch.float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7caa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_active_index: 243\n"
     ]
    }
   ],
   "source": [
    "if curriculum_type == 'base2':\n",
    "    generated_harmony = structured_progressive_generate(\n",
    "        model=model,\n",
    "        melody_grid=melody_grid,\n",
    "        conditioning_vec=conditioning_vec,\n",
    "        num_stages=10,\n",
    "        mask_token_id=tokenizer.mask_token_id,\n",
    "        temperature=1.0,\n",
    "        strategy='topk'\n",
    "    )\n",
    "else:\n",
    "    generated_harmony = random_progressive_generate(\n",
    "        model=model,\n",
    "        melody_grid=melody_grid,\n",
    "        conditioning_vec=conditioning_vec,\n",
    "        num_stages=10,\n",
    "        mask_token_id=tokenizer.mask_token_id,\n",
    "        temperature=1.0,\n",
    "        strategy='topk',\n",
    "        pad_token_id=pad_token_id,      # token ID for <pad>\n",
    "        nc_token_id=nc_token_id,       # token ID for <nc>\n",
    "        force_fill=True         # disallow <pad>/<nc> before melody ends\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a895ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tokens\n",
      "['G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj']\n",
      "harmony_gt_tokens\n",
      "['B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:7', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'B:min', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'A:maj', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7', 'F#:min7']\n"
     ]
    }
   ],
   "source": [
    "output_tokens = []\n",
    "for i,t in enumerate(generated_harmony[0].tolist()):\n",
    "    output_tokens.append( tokenizer.ids_to_tokens[t] )\n",
    "print('output_tokens')\n",
    "print(output_tokens)\n",
    "\n",
    "harmony_gt_tokens = []\n",
    "for i,t in enumerate(harmony_gt[0].tolist()):\n",
    "    harmony_gt_tokens.append( tokenizer.ids_to_tokens[t] )\n",
    "print('harmony_gt_tokens')\n",
    "print(harmony_gt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e6d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = overlay_generated_harmony(encoded['melody_part'], output_tokens, encoded['ql_per_quantum'], encoded['skip_steps'])\n",
    "save_harmonized_score(score, out_path=\"harmonized_output.mxl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
